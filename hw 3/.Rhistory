install.packages("fields")
install.packages(c('chron','colorspace','codetools','DBI','devtools','dichromat','digest','doParallel', 'dplyr', 'fields',
'foreach', 'ggplot2','gridExtra','gtable','inline','iterators','knitr','labeling','lattice','lme4','mapproj','maps','munsell','proftools',
'proto','purrr', 'rbenchmark','RColorBrewer','Rcpp','reshape2','rJava','RSQLite','scales','spam',
'stringr','tidyr','xlsx','xlsxjars','xtable'), repos = "https://cran.cnr.berkeley.edu")
gap <- read.csv(file.path('..', 'data', 'gapminder-FiveYearData.csv'), stringsAsFactors = FALSE)
gap <- read.csv(file.path("F:\\r-bootcamp-fall-2019-master\\r-bootcamp-fall-2019-master\\data\\gapminder-FiveYearData.csv"), stringsAsFactors = FALSE)
gap2007 <- gap[gap$year == 2007, ]
ord <- order(gap$year, gap$lifeExp, decreasing = TRUE)
ord[1:5]
gm_ord <- gap[ord, ]
sortByCol <- function(data, col1, col2) {
# Sorts a matrix or dataframe based on two  columns
#
# Args:
#     data: a dataframe or matrix with at least columns
#                  and any number of rows
#     col1: a reference to the column to sort on
#     col2: a reference to the column to use for ties
#
# Returns:
#     <data> sorted in increasing order by the values
#     in the first column. Any ties should be broken by values
#     in the second column. The row pairs should be maintained
#     in this result
ord <- order(data[, col1], data[, col2], decreasing=TRUE)
sorted <- data[ord, ]
return(sorted)
}
identical(gm_ord, sortByCol(gap, "year", "lifeExp"))
sortByCol <- function(data, col1 = 1, col2 = 2) {
ord <- order(data[, col1], data[, col2], decreasing=TRUE)
sorted <- data[ord, ]
return(sorted)
}
identical(sortByCol(gap, 1, 2), sortByCol(gap))
identical(sortByCol(col2 = 2, data = gap, col1 = 1), sortByCol(gap, 1, 2))
pplot <- function(x, y, ...) {
plot(x, y, pch = 16, cex = 0.6, ...)
}
pplot(gap$gdpPercap, gap$lifeExp,  xlab = 'gdpPercap (log $)',
ylab = 'life expectancy (years)', log = 'x')
x <- 2
f <- function(y) {
return(x + y)
}
f(1)
g <- function(y) {
x <- 10
return(f(y))
}
g(1)
g <- function(y) {
f <- function(y) {
return(x + y)
}
x <- 10
return(f(y))
}
g(1)
3+2
'+'(3,2)
x[ , 2]
x <- matrix(runif(100), 10)
x[ , 2]
'['(x , , 2)
class(1)
class(runif)
class(function(x) x^2)
square <- function(x) x^2
class(square)
class(1)
class(runif)
class(function(x) x^2)
square <- function(x) x^2
class(square)
dim(x)
?matrix
function miniszero(x) {
x[x<0] = 0
}
function miniszero(x) {
x[(x<0)] <- 0
}
function miniszero(x) {
vals <- x < 0
}
?function
()
}
?function()
}
help("function")
miniszero <- function (x) {
vals <- x < 0
}
miniszero <- function (x) {
x[x < 0] = 0
}
abc = [ 1, 2, 3, -4, 5 ,-7,9]
abc
miniszero(abc)
abc
miniszero <- function (x) {
x[x < 0] = 0
return x
}
miniszero <- function (x) {
x[x < 0] = 0
return x
}
miniszero <- function (x) {
x[x < 0] = 0
return(x)
}
abc = [ 1, 2, 3, -4, 5 ,-7,9]
abc = c(1, 2, 3, -4, 5 ,-7,9)
abc
miniszero(abc)
abc
abc = miniszero(abc)
abc
# NOT run
install.packages('dplyr')
library(dplyr)
year_country_gdp_dplyr <- select(gap, year, country, gdpPercap)
head(year_country_gdp_dplyr)
year_country_gdp_base <- gap[,c("year", "country", "gdpPercap")]
head(year_country_gdp_base)
# checking equivalence: TRUE indicates an exact match between these objects
all.equal(year_country_gdp_dplyr, year_country_gdp_base)
year_country_gdp <- gap %>% select(year, country, gdpPercap)
dim(year_country_gdp)
year_country_gdp_africa <- gap %>%
filter(continent == "Africa") %>%
select(year,country,gdpPercap)
dim(year_country_gdp_africa)
gdp_bycontinents <- gap %>%
group_by(continent) %>%
summarize(mean_gdpPercap = mean(gdpPercap))
head(gdp_bycontinents)
gdp_pop_bycontinents_byyear <- gap %>%
group_by(continent, year) %>%
summarize(mean_gdpPercap = mean(gdpPercap),
sd_gdpPercap = sd(gdpPercap),
mean_pop = mean(pop),
sd_pop = sd(pop))
head(gdp_pop_bycontinents_byyear)
head(gdp_pop_bycontinents_byyear)
gap_with_extra_vars <- gap %>%
group_by(continent, year) %>%
mutate(mean_gdpPercap = mean(gdpPercap),
sd_gdpPercap = sd(gdpPercap),
mean_pop = mean(pop),
sd_pop = sd(pop)) %>%
arrange(desc(year), continent) # `desc()` puts things ins descending order
head(gap_with_extra_vars)
gdp_pop_bycontinents_byyear <- gap %>%
mutate(gdp_billion = gdpPercap*pop/10^9) %>%
group_by(continent, year) %>%
summarize(mean_gdpPercap = mean(gdpPercap),
sd_gdpPercap = sd(gdpPercap),
mean_pop = mean(pop),
sd_pop = sd(pop),
mean_gdp_billion = mean(gdp_billion),
sd_gdp_billion = sd(gdp_billion))
head(gdp_pop_bycontinents_byyear)
gap_with_extra_vars <- gap %>%
group_by(continent, year) %>%
mutate(mean_gdpPercap = mean(gdpPercap),
sd_gdpPercap = sd(gdpPercap),
mean_pop = mean(pop),
sd_pop = sd(pop)) %>%
arrange(desc(year), continent) # `desc()` puts things ins descending order
head(gap_with_extra_vars)
gap %>% select(continent, year) %>% tail()
head(gap)
# Load the "tidyr" package (necessary every new R session)
library(tidyr)
gap_wide <- read.csv("../data/gapminder_wide.csv", stringsAsFactors = FALSE)
gap_wide <- read.csv("F:\\r-bootcamp-fall-2019-master\\r-bootcamp-fall-2019-master\\modulesgapminder_wide.csv", stringsAsFactors = FALSE)
head(gap_wide)
gap_wide <- read.csv("F:\\r-bootcamp-fall-2019-master\\r-bootcamp-fall-2019-master\\modulesgapminder_wide.csv", stringsAsFactors = FALSE)
getwd()
setwd("C:\\Users\\Aditya Peshin\\Desktop\\Studies\\UC Berkeley\\Fall 2019\\242 - Applications in Data Analysis\\Assignments\\hw 3")
getwd()
library(rpart)
library(rpart.plot)
library(caret)
library(randomForest)
library(gbm)
library(caTools)
library(dplyr)
library(ggplot2)
library(GGally)
library(ROCR)
library(e1071)
library(tidyverse)
library(MASS)
letters_orig <- read.csv("Letters.csv")
letters_orig$isB = as.factor(letters_orig$letter == "B")
#setting seed
set.seed(456)
#splitting into training and testing set
train.ids = sample(nrow(letters_orig), 0.65*nrow(letters_orig))
letters_orig.train = letters_orig[train.ids,]
letters_orig.test = letters_orig[-train.ids,]
set.seed(456)
table (letters_orig.test$isB)
# False True
# 788   303
baseline_acc <- (788) / nrow(letters_orig.test)
baseline_acc
set.seed(456)
mod1 <- glm(isB ~ . - letter, data = letters_orig.train, family = "binomial" )
summary(mod1)
# making the prediction on the test data
pred1 <- predict(mod1, newdata = letters_orig.test, type = "response")
table(letters_orig.test$isB, pred1>= 0.5)
#        FALSE TRUE
# FALSE   760   28
# TRUE     30  273
logistic_acc <- (273 + 760)/(273+760+30+28)
logistic_acc
set.seed(456)
pred_logistic <- prediction(pred1, letters_orig.test$isB)
auc_logistic <- performance(pred_logistic, measure = "auc")
auc_logistic <- auc_logistic@y.values[[1]]
# The value of AUC is 0.97966
set.seed(456)
cpVals = data.frame(cp = seq(0, .04, by=.002))
model_cart <- train(isB ~ . - letter,
data = letters_orig.train,
method = "rpart",
tuneGrid = cpVals,
trControl = trainControl(method = "cv", number=10),
metric = "Accuracy" )
model_cart$results
model_cart
set.seed(456)
pred2 <- predict(model_cart$finalModel, newdata = letters_orig.test, type = "prob")
table(letters_orig.test$isB, pred2[,2] >= 0.5)
#         FALSE TRUE
# FALSE     764   24
# TRUE       56  247
cart_acc <- (247 + 764)/(247+764+24+56)
cart_acc
set.seed(456)
model_randomforest <- randomForest(as.factor(isB) ~.-letter,
data = letters_orig.train)
# Predicting the outcomes
pred_rf <- predict(model_randomforest, newdata = letters_orig.test)
table(pred_rf, letters_orig.test$isB)
# pred_rf   FALSE TRUE
#     FALSE   781   22
#     TRUE      7  281
randomforest_acc <- (781 + 281)/ (781+281+7+22)
randomforest_acc
randomforest_acc <- (781 + 282)/ (781+281+7+22)
randomforest_acc
set.seed(456)
table(letters_orig.train$letter)
#  A   B   P   R
# 546 463 520 496
# Thus, the prediction for every observation is 'A'
table(letters_orig.test$letter)
#    A   B   P   R
#  243 303 283 262
baseline_acc_part_b <- 243 / (243 + 303 + 283 + 262)
baseline_acc_part_b
# The value of accuracy is 0.2227 for the baseline model
set.seed(456)
model_lda <- lda(letter~.-isB,
data = letters_orig.train)
pred_lda <- predict(model_lda, newdata = letters_orig.test)
pred_lda_class <- pred_lda$class
pred_lda_probs <- pred_lda$posterior
tab <- table(letters_orig.test$letter, pred_lda_class)
tab
lda_accuracy_part_b <- sum(diag(tab))/ sum(tab)
lda_accuracy_part_b
set.seed(456)
cpVals_part_b = data.frame(cp = seq(0, .002, by=.0001))
model_cart_part_b <- train(letter ~ . - isB,
data = letters_orig.train,
method = "rpart",
tuneGrid = cpVals_part_b,
trControl = trainControl(method = "cv", number=10),
metric = "Accuracy" )
model_cart_part_b$results
model_cart_part_b
model_bagging
model_cart_part_b$results
model_cart_part_b
set.seed(456)
cpVals_part_b = data.frame(cp = seq(0, .01, by=.001))
model_cart_part_b <- train(letter ~ . - isB,
data = letters_orig.train,
method = "rpart",
tuneGrid = cpVals_part_b,
trControl = trainControl(method = "cv", number=10),
metric = "Accuracy" )
model_cart_part_b$results
model_cart_part_b
set.seed(456)
cpVals_part_b = data.frame(cp = seq(0, .02, by=.001))
model_cart_part_b <- train(letter ~ . - isB,
data = letters_orig.train,
method = "rpart",
tuneGrid = cpVals_part_b,
trControl = trainControl(method = "cv", number=10),
metric = "Accuracy" )
model_cart_part_b$results
model_cart_part_b
set.seed(456)
cpVals_part_b = data.frame(cp = seq(0, .001, by=.0001))
model_cart_part_b <- train(letter ~ . - isB,
data = letters_orig.train,
method = "rpart",
tuneGrid = cpVals_part_b,
trControl = trainControl(method = "cv", number=10),
metric = "Accuracy" )
model_cart_part_b$results
model_cart_part_b
set.seed(456)
pred_cart_part_b <- predict(model_cart_part_b$finalModel, newdata = letters_orig.test, type = "prob")
pred_cart_part_b
pred_cart_part_b.extended <- mutate(as.data.frame(pred_cart_part_b), Pred = ifelse(A>=0.5, 'A', ifelse(B>=0.5, "B", ifelse(P>=0.5, "P" , "R"))))
tab_cart_part_b <- table(letters_orig.test$letter, pred_cart_part_b.extended$Pred)
tab_cart_part_b
cart_acc_part_b <- (sum(diag(tab_cart_part_b)))/ sum(tab_cart_part_b)
cart_acc_part_b
set.seed(456)
ncol(letters_orig.test)
# The number of columns are 18
model_bagging <- randomForest(letter ~ . - isB,
data = letters_orig.train,
mtry = 16 )
model_bagging
# Predicting the outcomes
set.seed(456)
pred_bagging <- predict(model_bagging, newdata = letters_orig.test)
pred_bagging
# Confusion Matrix
bagging_tab <- table(pred_bagging, letters_orig.test$letter)
bagging_tab
bagging_acc <- sum(diag(bagging_tab))/sum(bagging_tab)
bagging_acc
set.seed(456)
mtry_part_b = data.frame(mtry = seq(1, 16, by=1))
model_randomforests_part_b <- train(letter ~ . - isB,
data = letters_orig.train,
method = "rf",
tuneGrid = mtry_part_b,
trControl = trainControl(method = "cv", number=10),
metric = "Accuracy" )
model_randomforests_part_b$results
final_rf_part_b <- model_randomforests_part_b$finalModel
final_rf_part_b
set.seed(456)
pred_rf_part_b <- predict(final_rf_part_b, letters_orig.test)
pred_rf_part_b
tab_rf_part_b <- table(pred_rf_part_b, letters_orig.test$letter)
tab_rf_part_b
rf_acc_part_b <- sum(diag(tab_rf_part_b))/sum(tab_rf_part_b)
rf_acc_part_b
rf_acc_part_b <- sum(diag(tab_rf_part_b))/sum(tab_rf_part_b)
rf_acc_part_b
set.seed(456)
model_boosting <- gbm(letter ~ . -isB,
data = letters_orig.train,
distribution = "multinomial",
n.trees = 3300,
interaction.depth = 10)
set.seed(456)
pred_boost <- predict(model_boosting, newdata = letters_orig.test, n.trees = 3300, type = "response")
pred_boost
final_pred_part_b = apply(pred_boost, 1, which.max)
final_pred_part_b = factor(final_pred_part_b, levels = c(1,2,3,4), labels = c("A", "B", "P", "R"))
tab_boosting_part_b <- table(final_pred_part_b, letters_orig.test$letter)
tab_boosting_part_b
boosting_acc <- sum(diag(tab_boosting_part_b))/sum(tab_boosting_part_b)
boosting_acc
set.seed(456)
pred2 <- predict(model_cart$finalModel, newdata = letters_orig.test, type = "prob")
table(letters_orig.test$isB, pred2[,2] >= 0.5)
#         FALSE TRUE
# FALSE     768   20
# TRUE       62  241
cart_acc <- (241 + 768)/(247+764+24+56)
cart_acc
#         FALSE TRUE
# FALSE     768   20
# TRUE       62  241
cart_acc <- (241 + 768)/(241+20+62+768)
cart_acc
set.seed(456)
model_randomforest <- randomForest(as.factor(isB) ~.-letter,
data = letters_orig.train)
# Predicting the outcomes
pred_rf <- predict(model_randomforest, newdata = letters_orig.test)
# Confusion Matrix
table(pred_rf, letters_orig.test$isB)
# pred_rf   FALSE TRUE
#     FALSE   781   21
#     TRUE      7  282
randomforest_acc <- (781 + 282)/ (781+281+7+22)
randomforest_acc
set.seed(456)
cpVals_part_b = data.frame(cp = seq(0, .001, by=.0001))
model_cart_part_b <- train(letter ~ . - isB,
data = letters_orig.train,
method = "rpart",
tuneGrid = cpVals_part_b,
trControl = trainControl(method = "cv", number=10),
metric = "Accuracy" )
model_cart_part_b$results
model_cart_part_b
set.seed(456)
pred_cart_part_b <- predict(model_cart_part_b$finalModel, newdata = letters_orig.test, type = "prob")
pred_cart_part_b
pred_cart_part_b.extended <- mutate(as.data.frame(pred_cart_part_b), Pred = ifelse(A>=0.5, 'A', ifelse(B>=0.5, "B", ifelse(P>=0.5, "P" , "R"))))
tab_cart_part_b <- table(letters_orig.test$letter, pred_cart_part_b.extended$Pred)
tab_cart_part_b
cart_acc_part_b <- (sum(diag(tab_cart_part_b)))/ sum(tab_cart_part_b)
cart_acc_part_b
set.seed(456)
cpVals_part_b = data.frame(cp = seq(0, .002, by=.0001))
model_cart_part_b <- train(letter ~ . - isB,
data = letters_orig.train,
method = "rpart",
tuneGrid = cpVals_part_b,
trControl = trainControl(method = "cv", number=10),
metric = "Accuracy" )
model_cart_part_b$results
model_cart_part_b
set.seed(456)
pred_cart_part_b <- predict(model_cart_part_b$finalModel, newdata = letters_orig.test, type = "prob")
pred_cart_part_b
pred_cart_part_b.extended <- mutate(as.data.frame(pred_cart_part_b), Pred = ifelse(A>=0.5, 'A', ifelse(B>=0.5, "B", ifelse(P>=0.5, "P" , "R"))))
tab_cart_part_b <- table(letters_orig.test$letter, pred_cart_part_b.extended$Pred)
tab_cart_part_b
cart_acc_part_b <- (sum(diag(tab_cart_part_b)))/ sum(tab_cart_part_b)
cart_acc_part_b
set.seed(456)
ncol(letters_orig.test)
# The number of columns are 18
model_bagging <- randomForest(letter ~ . - isB,
data = letters_orig.train,
mtry = 16 )
model_bagging
set.seed(456)
pred_bagging <- predict(model_bagging, newdata = letters_orig.test)
pred_bagging
# Confusion Matrix
bagging_tab <- table(pred_bagging, letters_orig.test$letter)
bagging_tab
bagging_acc <- sum(diag(bagging_tab))/sum(bagging_tab)
bagging_acc
set.seed(456)
mtry_part_b = data.frame(mtry = seq(1, 16, by=1))
model_randomforests_part_b <- train(letter ~ . - isB,
data = letters_orig.train,
method = "rf",
tuneGrid = mtry_part_b,
trControl = trainControl(method = "cv", number=10),
metric = "Accuracy" )
model_randomforests_part_b$results
set.seed(456)
mtry_part_b = data.frame(mtry = seq(1, 16, by=1))
model_randomforests_part_b <- train(letter ~ . - isB,
data = letters_orig.train,
method = "rf",
tuneGrid = mtry_part_b,
trControl = trainControl(method = "cv", number=10),
metric = "Accuracy" )
model_randomforests_part_b$results
final_rf_part_b <- model_randomforests_part_b$finalModel
final_rf_part_b
set.seed(456)
pred_rf_part_b <- predict(final_rf_part_b, letters_orig.test)
pred_rf_part_b
tab_rf_part_b <- table(pred_rf_part_b, letters_orig.test$letter)
tab_rf_part_b
rf_acc_part_b <- sum(diag(tab_rf_part_b))/sum(tab_rf_part_b)
rf_acc_part_b
set.seed(456)
model_boosting <- gbm(letter ~ . -isB,
data = letters_orig.train,
distribution = "multinomial",
n.trees = 3300,
interaction.depth = 10)
set.seed(456)
pred_boost <- predict(model_boosting, newdata = letters_orig.test, n.trees = 3300, type = "response")
pred_boost
final_pred_part_b = apply(pred_boost, 1, which.max)
final_pred_part_b = factor(final_pred_part_b, levels = c(1,2,3,4), labels = c("A", "B", "P", "R"))
tab_boosting_part_b <- table(final_pred_part_b, letters_orig.test$letter)
tab_boosting_part_b
boosting_acc <- sum(diag(tab_boosting_part_b))/sum(tab_boosting_part_b)
boosting_acc
bagging_tab
bagging_acc <- sum(diag(bagging_tab))/sum(bagging_tab)
bagging_acc
model_cart
